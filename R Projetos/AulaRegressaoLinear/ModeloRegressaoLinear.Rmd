---
title: "Data Science - Regressão Linear"
output: 
  html_document: 
  theme: cosmo
---

<style type="text/css">
.main-container {
  max-width: 90% !important;
  margin: auto;
}
</style>
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## Preparação

Pacotes para aula.

```{r, cache=FALSE}
# install.packages("ftsa", dependencies = TRUE)
# install.packages("rsample", dependencies = TRUE)
# install.packages("car", dependencies = TRUE)
# install.packages("corrplot", dependencies = TRUE)
# install.packages("knitr", dependencies = TRUE)
# install.packages("tidyverse", dependencies = TRUE)
# install.packages("lubridate", dependencies = TRUE)
# install.packages("readr", dependencies = TRUE)
# install.packages("skimr", dependencies = TRUE)
# install.packages("broom", dependencies = TRUE)
# install.packages("GGally", dependencies = TRUE)

# Carrega pacote
library(rsample)
library(ftsa)
library(car)
library(corrplot)
library(knitr)
library(GGally)
library(tidyverse)
library(lubridate)
library(readr)
library(skimr)
library(broom)
```

## Regressão Linear Simples

### Exemplo simples para didática

A base de dados refere-se ao registro hipotético do consumo de kilos de sorvete e a temperatura média durante esse consumo. 

```{r, cache=FALSE}
# Consumo de sorvete
consumoSorvete <- tibble(
  KgSorvete = c(
    400L, 
    500L, 
    700L, 
    790L, 
    870L, 
    932L, 
    1100L, 
    1370L, 
    1490L, 
    1670L, 
    1800L
  ),
  Temperatura = 22L:32L
)
```

### Dispersão dos dados (scartter plot)

Podemos observar no gráfico de dispersão dos dados que há uma tendência linear.

```{r}
grafico <- consumoSorvete %>% 
  ggplot(
    aes(
      x = Temperatura,
      y = KgSorvete
    )
  ) +
  geom_point() +
  ylab(
    label = "Consumo de sorvete (Kg)"
  )

grafico
```

### Modelo de regressão linear simples

$$
y = \alpha + \beta x + erro
$$
```{r, cache=FALSE}
modelo <- lm(
  formula = KgSorvete ~ Temperatura,
  data = consumoSorvete
)

grafico +
  stat_smooth(
    method = "lm",
    formula = y ~ x,
    geom = "smooth",
    se = TRUE,
    level = 0.95
  )

# Resultados do modelo
summary(modelo)
```

Call: Indica a chamada da função utilizada para realizar a regressão linear. 

Residuals: Resumo dos resíduos da regressão (diferença entre os valores reais e os valores previstos pelo modelo). Mostra o valor mínimo, primeiro quartil (25º percentil), mediana (50º percentil), terceiro quartil (75º percentil) e valor máximo dos resíduos.

Intercept: O coeficiente para o termo de intercepção (constante) $-2733.273$.

Temperatura: O coeficiente associado à variável independente Temperatura. Isso indica que, para cada aumento de uma unidade na temperatura, o valor previsto de KgSorvete aumenta em 140.364 unidades.

Significance codes: Os códigos de significância mostram o nível de significância estatística dos coeficientes. Neste caso, os coeficientes têm valores extremamente baixos (indicados por '***'), o que significa que ambos os coeficientes são altamente significativos.

Residual standard error: Esta é uma estimativa do desvio padrão dos resíduos, que é uma medida da dispersão dos pontos em relação à linha de regressão. Quanto menor esse valor, melhor o ajuste do modelo aos dados observados.

```{r, cache=FALSE}
modelo %>% 
  augment() %>% 
  ggplot(
    aes(
      x = Temperatura,
      y = KgSorvete
    )
  ) +
  geom_point() +
  stat_smooth(
    method = lm, 
    se = FALSE
  ) +
  geom_segment(
    aes(
      xend = Temperatura, 
      yend = .fitted
    ), 
    color = "red", 
    size = 0.3
  ) +
  ylab(
    label = "Consumo de sorvete (Kg) e resíduos"
  )
```

Degrees of freedom: Referem ao número de observações (pontos de dados) menos o número de parâmetros estimados no modelo (intercepto, inclinação, etc.).

* Número total de observações (pontos de dados): 11 (uma vez que há 11 valores para as variáveis `KgSorvete` e `Temperatura`).

* Número de parâmetros estimados no modelo: 2 (intercepto e coeficiente para Temperatura).

Portanto, os graus de liberdade do erro (residual) seriam $11 - 2 = 9$. O valor é utilizado para calcular a estatística F.

* F-statistic e p-value: A estatística F é usada para testar a significância geral do modelo de regressão. Com p-value extremamente baixo (3.437e-09), o modelo como um todo é altamente significativo.

* Multiple R-squared e Adjusted R-squared: O coeficiente de determinação (R-squared) é uma medida da proporção da variabilidade na variável dependente que é explicada pelo modelo. Cerca de 98.23% da variabilidade em `KgSorvete` é explicada pela variável `Temperatura`. O Adjusted R-squared leva em consideração o número de variáveis independentes no modelo e ajusta o R-squared para penalizar o uso excessivo de variáveis independentes.

Então, pela modelagem o $y$ é o consumo de sorvete em Kg. Assim, gostaríamos de estimar, considerando essa modelagem, qual seria o consumo de sorvete se a temperatura chegasse a 40°C ? 

$$
y = -2733.273 + (140.364 * x)
$$

$$2881.287 = -2733.273 + (140.364 * 40)$$

O consumo de sorvete estimado é de 2881.287 Kg.

## Regressão Linear Multivariada

Nesse caso, há $n$ variáveis independentes.

$$
y = \alpha + (\beta_1 * x_1) + \dots + (\beta_n * x_n) + err
$$
### Carga dos dados

```{r, cache=FALSE}
# Carrega o arquivo csv
dados <- read_delim(
  file = "https://www.ufrgs.br/wiki-r/images/3/3d/Customer_shopping_data.csv",
  delim = ","
) %>% 
  transmute(
    price,
    gender = factor(gender),
    age = as.integer(age),
    category = factor(category),
    payment_method = factor(payment_method),
    shopping_mall = factor(shopping_mall),
    Mes = month(invoice_date)
  )

# Dados originais
dados %>% 
  head(n = 15) %>% 
  kable()
```

### Modelo com todas as variáveis

```{r, cache=FALSE}
modelo <- lm(
  formula = price ~ .,
  data = dados
)

summary(modelo)
```

Observem as médias por `category`.

```{r, cache=FALSE}
dados %>% 
  select(category, price) %>% 
  group_by(category) %>% 
  skim()
```

### Modelo com seleção de variáveis

É recomentável reduzir a complexidade do modelo removendo variáveis irrelevantes, ruidozas ou correlacionadas. Um dos métodos recomendados para modelos de regressão é o Step Wise. 

```{r, cache=FALSE}
modelo <- lm(
  formula = price ~ .,
  data = dados
) %>% 
  step()

summary(modelo)
```

## Regressão linear e correlações

### Carrega dados

```{r}
# Carrega o arquivo csv
dadosRealEstate <- read_delim(
  file = "https://www.ufrgs.br/wiki-r/images/5/5f/RealEstate.csv",
  delim = ","
) %>% 
  select(-No) %>% # Remove o identificador de cada linha (ID)
  setNames(c("DataTransacao", "IdadeCasa", "DistanciaTransportePublico", "LojasProximas", "Latitude", "Longitude", "PrecoPorUnidadeArea"))  

# Dados originais
dadosRealEstate %>% 
  head(n = 15) %>% 
  kable()
```

#### Análise descritiva

```{r}
# Dados originais
dadosRealEstate %>% 
  skim()
```

#### Remoção de outliers

```{r}
# Dados originais
dados <- dadosRealEstate %>% 
  filter(
    PrecoPorUnidadeArea > quantile(PrecoPorUnidadeArea, 0.025),
    PrecoPorUnidadeArea < quantile(PrecoPorUnidadeArea, 0.975),
    DistanciaTransportePublico < quantile(DistanciaTransportePublico, 0.95)
  ) 

# Dados originais
dados %>% 
  skim()
```

### Correlações

```{r, out.width="70%"}
corrplot.mixed(
  corr = dados %>% 
    cor(),
  order = "FPC", 
  lower = "number", 
  upper = "square",
  tl.pos = "lt",
  tl.col = "black"
)
```

```{r, fig.align='center'}
dados %>% 
  rename_all(
    .funs = str_sub, end = 3
  ) %>% 
  ggpairs(
    lower = list(continuous = wrap("points", size = 0.5))
  ) +
  theme(
    axis.text.x = element_text(
      size = 5
    ),
    axis.text.y = element_text(
      size = 5
    )
  )
```

### Modelo de regressão

```{r}
# Cria modelo
modelo <- lm(
  formula = PrecoPorUnidadeArea ~ .,
  data = dados
)

# Informacoes do modelo
summary(modelo)
```

### Modelo de regressão com step wise

```{r}
# Cria modelo
modeloStep <- lm(
  formula = PrecoPorUnidadeArea ~ .,
  data = dados
) %>% 
  step()

# Informacoes do modelo
summary(modeloStep)
```

### Predição

* Data da transação: $2013.15$

* Idade da casa: $17.47$

* Distância para o transporte público: $855.29$.

* Quantidade de lojas próximas: $4.31$.

* Latitude: $24.97$.

```{r}
predict(
  modeloStep,
  tibble(
    DataTransacao = 2013.15,
    IdadeCasa = 17.47,
    DistanciaTransportePublico = 855.29,
    LojasProximas = 4.31,
    Latitude = 24.97
  )  
)
```

## Referências

Bowerman, Bruce L. and  O'Connell, Richard T. Linear Statistical Models. Duxbury classic series. Edição	2. Editora	Thomson Wadsworth, 1990. ISBN	9780534923266

Field, A., Miles, J. and Field, Z. (2012) Discovering Statistics Using R. Sage Publications Ltd., London.

Heldt, Rodrigo. (2023) ANÁLISE DE PESQUISA EM ADMINISTRAÇÃO - Métodos Quantitativos. https://rheldt.com/regressaolinear.html#multicolinearidade

Menard, S. (1995). Applied logistic regression analysis (Sage university paper series on quantitative application in the social sciences, series no. 106) (2nd ed.). ThousandOaks, CA: Sage.
